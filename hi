#!/usr/bin/python3
import requests, os, sys

try :
	from rich import print
except ImportError:
	pass

API_KEY = os.getenv('PERPLEXITY_API_KEY')
if not API_KEY:
	print("Please set the PERPLEXITY_API_KEY environment variable to your api key")
	print("You can get an API key by signing up at https://www.perplexity.ai/settings/api")
	print("Then set the API key using the following command:")
	print("	export PERPLEXITY_API_KEY=your_api_key")
	print ("come back when you have a API_KEY")
	exit()

possible_models = ["llama-3.1-sonar-small-128k-chat", "llama-3.1-sonar-large-128k-chat"]
online_models = ["llama-3.1-sonar-small-128k-online", "llama-3.1-sonar-large-128k-online"]

headers = {
	"accept": "application/json",
	"content-type": "application/json",
	"authorization": "Bearer " + API_KEY
}

url = "https://api.perplexity.ai/chat/completions"

def color(text, color):
	if 'rich' in sys.modules:
		return f"[{color}]{text}[/]"
	return text

def printAvailableModels():
	print("\t Available models:")
	for i in range(len(possible_models)):
		print(f"		[{i}] - {possible_models[i]}")
	print("\t Online models:")
	print(f"		so - {online_models[0]}")
	print(f"		lo - {online_models[1]}")
	

def pick_model(model):
	if not model:
		return possible_models[0]
	if model.isdigit() and int(model) < len(possible_models):
		model = possible_models[int(model)]
	if model is not None and (model in possible_models or model in online_models):
		return model
	if model == "so" or model == "lo":
		return online_models[0] if model == "so" else online_models[1] 
	if model != "?":
		print(f'''Invalid model name, the model will be set to {possible_models[0]}''')
		return possible_models[0]
	printAvailableModels()
	model = input(f'''Choose a model (press enter for {possible_models[0]}): ''')
	return pick_model(model)

def chat_loop(question: str, model: str = possible_models[0], context: str = "Be precise and concise", single_use: bool = True):
	chat_payload = {
		"model": model
	}
	if model in possible_models and context: #ie offline model
		chat_payload["messages"] = [
				{
					"role": "system",
					"content": context
				}
			]
	else:
		chat_payload["messages"] = []
		single_use = True
	while (question != "exit"):
		if (single_use == False):
			print(color("You: ", "blue"), end="")
			question = input()
			if not question or question.lower() == "new chat":
				newchat_bool = input("--> Start a new chat (y/n)? \n\t")
				if newchat_bool.lower() == 'yes' or newchat_bool.lower() == 'y':
					chat_payload["messages"] = []
					print(color("---NEW CHAT---", "cyan"))
				else:
					print(color("/^.^\\ ", "purple" ) + "Lets continue our little chat")
				continue
			elif (question == "change model"):
				print(color("/^.^\\ ", "purple" ))
				model = pick_model("?")
				print(color("/^.^\\ ", "purple" ) + "Using " + model + " now")
				continue
			elif (question == "exit"):
				exit()
		chat_payload["messages"].append({
			"role": "user",
			"content": question
		})
		response = requests.post(url, json=chat_payload, headers=headers)
		if response.status_code != 200:
			print(color("Error: " + response.text, "red"))
			exit()
		chat_payload["messages"].append({
			"role": "assistant",
			"content": response.json()["choices"][0]["message"]["content"]
		})
		message = response.json()["choices"][0]["message"]["content"]
		if (single_use):
			print(message)
			return
		print(color("/^.^\\ ", "purple" ) + message)


def read_promt():
	prompt = sys.argv[1]
	if not sys.stdin.isatty():
		bits = []
		stdin_prompt = sys.stdin.read()
		if prompt:
			bits.append(prompt)
			bits.append("\n```\n")
			bits.append(stdin_prompt)
			bits.append("\n```")
		elif stdin_prompt:
			bits.append(stdin_prompt)
		prompt = "".join(bits)
	return prompt

def main(): # params
	if len(sys.argv) < 2 or sys.argv[1] == "help" or sys.argv[1] == "?" or sys.argv[1] == "h" or sys.argv[1] == "about" or sys.argv[1] == "-h" or not sys.argv[1]:
		print("welcome to the perplexity command line ai!")
		print(f'''
		This is a simple command line interface to interact with the perplexity api in one of two ways: 
		- get a response to a question
		- chat with the bot.
		To get a response to a question, use the following syntax:
		- CMD "Question" "Model (Optinal)" "System prompt (Optinal)"
		E.g. hi "What is the capital of Nigeria?" 0 "Be precise and concise" 
		To chat with the bot, use the following syntax:
		- CMD "chat" "Model (Optinal)" "System prompt (Optinal)"
		E.g. hi "chat" 1 "Be precise and concise" 
		To see the available models, use the following syntax:
		- hi "models"
		''')
		printAvailableModels()
		print(f'''
		To exit the chat, type "exit" at any time.
		''')
		exit()

	question = read_promt() # sys.argv[1]
	model = pick_model(sys.argv[2] if len(sys.argv) > 2 else None)
	context = sys.argv[3] if len(sys.argv) > 3 else "Be precise and concise"

	if question == "models":
		print("Available models:" + str(possible_models))
		exit()


	single_use = False if question == "chat" else True
	chat_loop(question, model, context, single_use)

if __name__ == "__main__":
	main()
